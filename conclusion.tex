\section{Conclusion}
\label{sec:conclusion}
This seminar paper presents the methods proposed by \textcite{hauzenberger_combining_2021} to combine shrinkage and sparsity in Bayesian VAR models while maintaining conjugacy using the well-known Minnesota prior setup. Maintaining conjugacy comes with the advantage of computational efficiency because key distributions such as the marginal posterior distributions and the predictive density are available in closed form and do not need to be approximated with MCMC methods. At the same time, the proposed ex-post sparsification of point-estimates relaxes the restrictive property of the Minnesota prior of not being able to have different predictors across VAR equations. The drawback of working with point-estimates only is solved by drawing and sparsifying repeatedly from the posterior as outlined in Section~\ref{subsubsec:approximation_of_sparse_posteriors}. This is computationally feasible because the utilized optimization algorithms converge very fast. In fact, the computational speed to estimate a conjugate model with the presented ex-post sparsification is by orders of magnitude faster than working with a non-conjugate SSVS prior BVAR model \parencite[Online Appendix]{hauzenberger_combining_2021}.

The forecasting application in Section~\ref{sec:forecasting_application} shows that sparsification in large models does not yield noteworthy performance gains for point-estimates but leads to slightly better density estimates with the exception of inflation forecasts. As investigated further in Section~\ref{subsec:forecasting_over_time}, one cannot recommend the usage of large, sparse BVAR models to central bank researchers who are interested in inflation forecasts due to the huge drop in forecasting accuracy during the financial crisis. The bias-variance trade-off has been identified as a potential reason for this drop. A sparse model is less likely to capture outliers due to the reduced predictive variance and performs worse in times of crisis which can be interpreted as outliers.

To conclude, the sparsification approach presented in this work combines desirable properties of the conjugate and non-conjugate model setup. While keeping the computational burden moderate the ex-post sparsification relaxes restrictive properties of the traditional conjugate Minnesota prior. However, it is worth noting that the forecasting application cannot be reproduced on a standard desktop computer in a timely manner even for the proposed conjugate model setup. Further research might be needed to improve computational speed such as the work by \textcite{chan_minnesota-type_2019} who adopt non-conjugate Minnesota-type adaptive hierarchical priors while keeping the computational burden very low using a custom posterior simulator.
